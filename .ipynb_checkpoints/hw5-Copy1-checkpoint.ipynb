{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe management\n",
    "import pandas as pd     \n",
    "# numerical computation\n",
    "import numpy as np\n",
    "# visualization library\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\", color_codes=True)\n",
    "sns.set_context(rc={\"font.family\":'sans',\"font.size\":24,\"axes.titlesize\":24,\"axes.labelsize\":24})   \n",
    "# import matplotlib and allow it to plot inline\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "#from sklearn.linear_model import Ridge,Lasso, LassoCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import hw5\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading the data preprocessed from files\n"
     ]
    }
   ],
   "source": [
    "print(\"loading the data preprocessed from files\")\n",
    "Y_test=np.loadtxt(\"Y_test.csv\",delimiter=\",\")\n",
    "X_test= pd.read_csv('X_test.csv', sep='\\t', encoding='utf-8')\n",
    "X_test=X_test.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLoading the models from files .pickle\")\n",
    "\n",
    "with open('model1.pickle', 'rb') as handle:\n",
    "    logReg = pickle.load(handle)\n",
    "with open('model2.pickle', 'rb') as handle:\n",
    "    model2 = pickle.load(handle)\n",
    "with open('model3.pickle', 'rb') as handle:\n",
    "    model3 = pickle.load(handle)\n",
    "with open('model4.pickle', 'rb') as handle:\n",
    "    model4 = pickle.load(handle)\n",
    "with open('model5.pickle', 'rb') as handle:\n",
    "    model5 = pickle.load(handle)\n",
    "with open('model7.pickle', 'rb') as handle:\n",
    "    model7 = pickle.load(handle)\n",
    "with open('model3_featureSelection.pickle', 'rb') as handle:\n",
    "    model3_featureSelection = pickle.load(handle)\n",
    "with open('model4_featureSelection.pickle', 'rb') as handle:\n",
    "    xgb_featureSelection = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 1\n",
      "Accuracy:\n",
      "0.7\n",
      "\n",
      "Model 2\n",
      "Accuracy:\n",
      "0.72\n",
      "\n",
      "Model 3\n",
      "Accuracy:\n",
      "0.76\n",
      "F1 score:\n",
      "0.8421052631578947\n",
      "\n",
      "Model 4\n",
      "Accuracy:\n",
      "0.735\n",
      "F1 score:\n",
      "0.8203389830508474\n",
      "\n",
      "Model 5\n",
      "Accuracy:\n",
      "0.705\n",
      "\n",
      "Model 6 is a NN but is present only in the jupiter notebook \n",
      " because of its very bad performances (due to the very small dataset)\n",
      "\n",
      "Model 7\n",
      "Accuracy:\n",
      "0.725\n",
      "F1 score:\n",
      "0.8220064724919094\n",
      "\n",
      "Model 3 with features selection\n",
      "Accuracy:\n",
      "0.745\n",
      "\n",
      "Model 4 with features selection\n",
      "Accuracy:\n",
      "0.74\n"
     ]
    }
   ],
   "source": [
    "def predictBaseline(test):\n",
    "    mostfrequent = 1\n",
    "    res=[]\n",
    "    for i in range(len(test)):\n",
    "        res.append(mostfrequent)\n",
    "    return np.array(res)\n",
    "print(\"\\n\\nThe baseline is to predict the most frequent class, it reaches the accuracy:\")\n",
    "predictions=predictBaseline(X_test)\n",
    "print(np.mean(predictions==Y_test))\n",
    "\n",
    "print(\"\\nModel 1\")\n",
    "print(\"Accuracy:\")\n",
    "predict_test = logReg.predict(X_test) \n",
    "print(np.mean(predict_test == Y_test))\n",
    "\n",
    "print(\"\\nModel 2\")\n",
    "print(\"Accuracy:\")\n",
    "prediction2=model2.predict(X_test)\n",
    "print(np.mean(prediction2 == Y_test))\n",
    "\n",
    "print(\"\\nModel 3\")\n",
    "print(\"Accuracy:\")\n",
    "predict3=model3.predict(X_test)\n",
    "print(np.mean(predict3 == Y_test))\n",
    "print(\"F1 score:\")\n",
    "print(f1_score(Y_test,predict3))\n",
    "\n",
    "print(\"\\nModel 4\")\n",
    "print(\"Accuracy:\")\n",
    "predict4=model4.predict(X_test)\n",
    "print(np.mean(predict4 == Y_test))\n",
    "print(\"F1 score:\")\n",
    "print(f1_score(Y_test,predict4))\n",
    "\n",
    "print(\"\\nModel 5\")\n",
    "print(\"Accuracy:\")\n",
    "predict5 = model5.predict(X_test)\n",
    "print(np.mean(predict5==Y_test))\n",
    "\n",
    "print(\"\\nModel 6 is a NN but is present only in the jupiter notebook \\n because of its very bad performances (due to the very small dataset)\")\n",
    "\n",
    "print(\"\\nModel 7\")\n",
    "print(\"Accuracy:\")\n",
    "pred7=model7.predict(X_test)\n",
    "print(np.mean(pred7==Y_test))\n",
    "print(\"F1 score:\")\n",
    "print(f1_score(Y_test,pred7))\n",
    "\n",
    "print(\"\\nModel 3 with features selection\")\n",
    "print(\"Accuracy:\")\n",
    "predict3_featureSelection=model3_featureSelection.predict(X_test[f])\n",
    "print(np.mean(predict3_featureSelection == Y_test))\n",
    "\n",
    "print(\"\\nModel 4 with features selection\")\n",
    "print(\"Accuracy:\")\n",
    "pred=xgb_featureSelection.predict(X_test[f])\n",
    "print(np.mean(pred == Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model persistence:\n",
    "#https://scikit-learn.org/stable/modules/model_persistence.html\n",
    "#save=pickle.dumps(model3)\n",
    "#model3= pickle.loads(s)\n",
    "#model3.predict(X_test)\n",
    "#-----------------\n",
    "#with open('model2.pickle', 'wb') as handle:\n",
    "#    pickle.dump(model2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#with open('model1.pickle', 'rb') as handle:\n",
    "#    b = pickle.load(handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
