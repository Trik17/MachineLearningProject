{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe management\n",
    "import pandas as pd             \n",
    "\n",
    "# numerical computation\n",
    "import numpy as np\n",
    "\n",
    "#import re\n",
    "\n",
    "# visualization library\n",
    "#import seaborn as sns\n",
    "#sns.set(style=\"white\", color_codes=True)\n",
    "#sns.set_context(rc={\"font.family\":'sans',\"font.size\":24,\"axes.titlesize\":24,\"axes.labelsize\":24})   \n",
    "\n",
    "\n",
    "# import matplotlib and allow it to plot inline\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "#for k-Means\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from datetime import datetime, timedelta, date\n",
    "#from scipy.stats import skew\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, ElasticNet, Lasso, LassoCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import pickle\\n\\na = {'hello': 'world'}\\n\\nwith open('filename.pickle', 'wb') as handle:\\n    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\\n\\nwith open('filename.pickle', 'rb') as handle:\\n    b = pickle.load(handle)\\n\\nprint a == b\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for model persistence:\n",
    "#https://scikit-learn.org/stable/modules/model_persistence.html\n",
    "\"\"\">>> from sklearn import svm\n",
    ">>> from sklearn import datasets\n",
    ">>> clf = svm.SVC(gamma='scale')\n",
    ">>> iris = datasets.load_iris()\n",
    ">>> X, y = iris.data, iris.target\n",
    ">>> clf.fit(X, y)  \n",
    "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "\n",
    ">>> import pickle\n",
    ">>> s = pickle.dumps(clf)\n",
    ">>> clf2 = pickle.loads(s)\n",
    ">>> clf2.predict(X[0:1])\n",
    "array([0])\n",
    ">>> y[0]\n",
    "0\"\"\"\n",
    "#---------------------\n",
    "\n",
    "\"\"\"import pickle\n",
    "\n",
    "a = {'hello': 'world'}\n",
    "\n",
    "with open('filename.pickle', 'wb') as handle:\n",
    "    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('filename.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "\n",
    "print a == b\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib #importlib.reload(WhatToReimport)\n",
    "import hw5\n",
    "importlib.reload(hw5)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=hw5.Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Music</th>\n",
       "      <th>Slow songs or fast songs</th>\n",
       "      <th>Dance</th>\n",
       "      <th>Folk</th>\n",
       "      <th>Country</th>\n",
       "      <th>Classical music</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Pop</th>\n",
       "      <th>Rock</th>\n",
       "      <th>Metal or Hardrock</th>\n",
       "      <th>...</th>\n",
       "      <th>Shopping centres</th>\n",
       "      <th>Branded clothing</th>\n",
       "      <th>Entertainment spending</th>\n",
       "      <th>Spending on looks</th>\n",
       "      <th>Spending on gadgets</th>\n",
       "      <th>Spending on healthy eating</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Number of siblings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1007.000000</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>1006.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>1005.000000</td>\n",
       "      <td>1003.000000</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>1004.000000</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>1008.000000</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>1007.000000</td>\n",
       "      <td>1010.000000</td>\n",
       "      <td>1008.00000</td>\n",
       "      <td>1003.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>1004.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.731877</td>\n",
       "      <td>3.328373</td>\n",
       "      <td>3.113320</td>\n",
       "      <td>2.288557</td>\n",
       "      <td>2.123383</td>\n",
       "      <td>2.956132</td>\n",
       "      <td>2.761905</td>\n",
       "      <td>3.471698</td>\n",
       "      <td>3.761952</td>\n",
       "      <td>2.361470</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234127</td>\n",
       "      <td>3.050595</td>\n",
       "      <td>3.201589</td>\n",
       "      <td>3.106256</td>\n",
       "      <td>2.870297</td>\n",
       "      <td>3.55754</td>\n",
       "      <td>20.433699</td>\n",
       "      <td>173.514141</td>\n",
       "      <td>66.405051</td>\n",
       "      <td>1.297809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.664049</td>\n",
       "      <td>0.833931</td>\n",
       "      <td>1.170568</td>\n",
       "      <td>1.138916</td>\n",
       "      <td>1.076136</td>\n",
       "      <td>1.252570</td>\n",
       "      <td>1.260845</td>\n",
       "      <td>1.161400</td>\n",
       "      <td>1.184861</td>\n",
       "      <td>1.372995</td>\n",
       "      <td>...</td>\n",
       "      <td>1.323062</td>\n",
       "      <td>1.306321</td>\n",
       "      <td>1.188947</td>\n",
       "      <td>1.205368</td>\n",
       "      <td>1.284970</td>\n",
       "      <td>1.09375</td>\n",
       "      <td>2.828840</td>\n",
       "      <td>10.024505</td>\n",
       "      <td>13.839561</td>\n",
       "      <td>1.013348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Music  Slow songs or fast songs        Dance         Folk  \\\n",
       "count  1007.000000               1008.000000  1006.000000  1005.000000   \n",
       "mean      4.731877                  3.328373     3.113320     2.288557   \n",
       "std       0.664049                  0.833931     1.170568     1.138916   \n",
       "min       1.000000                  1.000000     1.000000     1.000000   \n",
       "25%       5.000000                  3.000000     2.000000     1.000000   \n",
       "50%       5.000000                  3.000000     3.000000     2.000000   \n",
       "75%       5.000000                  4.000000     4.000000     3.000000   \n",
       "max       5.000000                  5.000000     5.000000     5.000000   \n",
       "\n",
       "           Country  Classical music      Musical          Pop         Rock  \\\n",
       "count  1005.000000      1003.000000  1008.000000  1007.000000  1004.000000   \n",
       "mean      2.123383         2.956132     2.761905     3.471698     3.761952   \n",
       "std       1.076136         1.252570     1.260845     1.161400     1.184861   \n",
       "min       1.000000         1.000000     1.000000     1.000000     1.000000   \n",
       "25%       1.000000         2.000000     2.000000     3.000000     3.000000   \n",
       "50%       2.000000         3.000000     3.000000     4.000000     4.000000   \n",
       "75%       3.000000         4.000000     4.000000     4.000000     5.000000   \n",
       "max       5.000000         5.000000     5.000000     5.000000     5.000000   \n",
       "\n",
       "       Metal or Hardrock         ...          Shopping centres  \\\n",
       "count        1007.000000         ...               1008.000000   \n",
       "mean            2.361470         ...                  3.234127   \n",
       "std             1.372995         ...                  1.323062   \n",
       "min             1.000000         ...                  1.000000   \n",
       "25%             1.000000         ...                  2.000000   \n",
       "50%             2.000000         ...                  3.000000   \n",
       "75%             3.000000         ...                  4.000000   \n",
       "max             5.000000         ...                  5.000000   \n",
       "\n",
       "       Branded clothing  Entertainment spending  Spending on looks  \\\n",
       "count       1008.000000             1007.000000        1007.000000   \n",
       "mean           3.050595                3.201589           3.106256   \n",
       "std            1.306321                1.188947           1.205368   \n",
       "min            1.000000                1.000000           1.000000   \n",
       "25%            2.000000                2.000000           2.000000   \n",
       "50%            3.000000                3.000000           3.000000   \n",
       "75%            4.000000                4.000000           4.000000   \n",
       "max            5.000000                5.000000           5.000000   \n",
       "\n",
       "       Spending on gadgets  Spending on healthy eating          Age  \\\n",
       "count          1010.000000                  1008.00000  1003.000000   \n",
       "mean              2.870297                     3.55754    20.433699   \n",
       "std               1.284970                     1.09375     2.828840   \n",
       "min               1.000000                     1.00000    15.000000   \n",
       "25%               2.000000                     3.00000    19.000000   \n",
       "50%               3.000000                     4.00000    20.000000   \n",
       "75%               4.000000                     4.00000    22.000000   \n",
       "max               5.000000                     5.00000    30.000000   \n",
       "\n",
       "           Height      Weight  Number of siblings  \n",
       "count  990.000000  990.000000         1004.000000  \n",
       "mean   173.514141   66.405051            1.297809  \n",
       "std     10.024505   13.839561            1.013348  \n",
       "min     62.000000   41.000000            0.000000  \n",
       "25%    167.000000   55.000000            1.000000  \n",
       "50%    173.000000   64.000000            1.000000  \n",
       "75%    180.000000   75.000000            2.000000  \n",
       "max    203.000000  165.000000           10.000000  \n",
       "\n",
       "[8 rows x 139 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010, 150)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values of the target feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Height', 20),\n",
       " ('Weight', 20),\n",
       " ('Passive sport', 15),\n",
       " ('Chemistry', 10),\n",
       " ('Geography', 9),\n",
       " ('Punk', 8),\n",
       " ('Latino', 8),\n",
       " ('Documentary', 8),\n",
       " ('Theatre', 8),\n",
       " ('Smoking', 8),\n",
       " ('Classical music', 7),\n",
       " ('Reggae, Ska', 7),\n",
       " ('Rock n roll', 7),\n",
       " ('Alternative', 7),\n",
       " ('Techno, Trance', 7),\n",
       " ('Countryside, outdoors', 7),\n",
       " ('Gardening', 7),\n",
       " ('Daily events', 7),\n",
       " ('Final judgement', 7),\n",
       " ('Criminal damage', 7),\n",
       " ('Compassion to animals', 7),\n",
       " ('Age', 7),\n",
       " ('Rock', 6),\n",
       " ('Swing, Jazz', 6),\n",
       " ('Movies', 6),\n",
       " ('PC', 6),\n",
       " ('Biology', 6),\n",
       " ('Reading', 6),\n",
       " ('Art exhibitions', 6),\n",
       " ('Writing', 6),\n",
       " ('Science and technology', 6),\n",
       " ('Friends versus money', 6),\n",
       " ('Giving', 6),\n",
       " ('Responding to a serious letter', 6),\n",
       " ('Number of siblings', 6),\n",
       " ('Gender', 6),\n",
       " ('Folk', 5),\n",
       " ('Country', 5),\n",
       " ('Psychology', 5),\n",
       " ('Economy Management', 5),\n",
       " ('Foreign languages', 5),\n",
       " ('Medicine', 5),\n",
       " ('Spiders', 5),\n",
       " ('Alcohol', 5),\n",
       " ('Prioritising workload', 5),\n",
       " ('Workaholism', 5),\n",
       " ('Self-criticism', 5),\n",
       " ('Empathy', 5),\n",
       " ('Socializing', 5),\n",
       " ('Energy levels', 5),\n",
       " ('Getting up', 5),\n",
       " ('Dance', 4),\n",
       " ('Hiphop, Rap', 4),\n",
       " ('Western', 4),\n",
       " ('Internet', 4),\n",
       " ('Cars', 4),\n",
       " ('Active sport', 4),\n",
       " ('Fun with friends', 4),\n",
       " ('Pets', 4),\n",
       " ('Reliability', 4),\n",
       " ('Loss of interest', 4),\n",
       " ('Funniness', 4),\n",
       " ('Decision making', 4),\n",
       " ('Judgment calls', 4),\n",
       " ('Hypochondria', 4),\n",
       " ('Cheating in school', 4),\n",
       " ('Mood swings', 4),\n",
       " ('Children', 4),\n",
       " ('Getting angry', 4),\n",
       " ('Happiness in life', 4),\n",
       " ('Small - big dogs', 4),\n",
       " ('Personality', 4),\n",
       " ('Finding lost valuables', 4),\n",
       " ('Questionnaires or polls', 4),\n",
       " ('Village - town', 4),\n",
       " ('House - block of flats', 4),\n",
       " ('Music', 3),\n",
       " ('Pop', 3),\n",
       " ('Metal or Hardrock', 3),\n",
       " ('Comedy', 3),\n",
       " ('Romantic', 3),\n",
       " ('Fantasy/Fairy tales', 3),\n",
       " ('Animated', 3),\n",
       " ('Mathematics', 3),\n",
       " ('Physics', 3),\n",
       " ('Religion', 3),\n",
       " ('Dancing', 3),\n",
       " ('Adrenaline sports', 3),\n",
       " ('Flying', 3),\n",
       " ('Heights', 3),\n",
       " ('Rats', 3),\n",
       " ('Healthy eating', 3),\n",
       " ('Writing notes', 3),\n",
       " ('Thinking ahead', 3),\n",
       " ('Elections', 3),\n",
       " ('Charity', 3),\n",
       " ('Waiting', 3),\n",
       " ('Appearence and gestures', 3),\n",
       " ('Unpopularity', 3),\n",
       " ('Life struggles', 3),\n",
       " ('Interests or hobbies', 3),\n",
       " ('Finances', 3),\n",
       " ('Entertainment spending', 3),\n",
       " ('Spending on looks', 3),\n",
       " ('Left - right handed', 3),\n",
       " ('Slow songs or fast songs', 2),\n",
       " ('Musical', 2),\n",
       " ('Horror', 2),\n",
       " ('Sci-fi', 2),\n",
       " ('War', 2),\n",
       " ('Action', 2),\n",
       " ('History', 2),\n",
       " ('Celebrities', 2),\n",
       " ('Shopping', 2),\n",
       " ('Darkness', 2),\n",
       " ('Borrowed stuff', 2),\n",
       " ('Changing the past', 2),\n",
       " ('God', 2),\n",
       " ('Punctuality', 2),\n",
       " ('Lying', 2),\n",
       " ('New environment', 2),\n",
       " ('Achievements', 2),\n",
       " ('Assertiveness', 2),\n",
       " ('Knowing the right people', 2),\n",
       " ('Public speaking', 2),\n",
       " (\"Parents' advice\", 2),\n",
       " ('Shopping centres', 2),\n",
       " ('Branded clothing', 2),\n",
       " ('Spending on healthy eating', 2),\n",
       " ('Only child', 2),\n",
       " ('Opera', 1),\n",
       " ('Thriller', 1),\n",
       " ('Politics', 1),\n",
       " ('Law', 1),\n",
       " ('Musical instruments', 1),\n",
       " ('Storm', 1),\n",
       " ('Ageing', 1),\n",
       " ('Dangerous dogs', 1),\n",
       " ('Fear of public speaking', 1),\n",
       " ('Keeping promises', 1),\n",
       " ('Fake', 1),\n",
       " ('Loneliness', 1),\n",
       " ('Health', 1),\n",
       " ('Education', 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls = d.data.isnull().sum()\n",
    "sorted([(x,y) for (x,y) in zip(nulls.index, nulls) if y>0], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to manage all these missing values. <br>\n",
    "First of all I will remove all the rows that have the target feature \"Empathy\" to null because they have no use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with Empathy that is null: 5\n",
      "Number of rows with Empathy that is null after: 0\n"
     ]
    }
   ],
   "source": [
    "#removing the rows in which the Empathy attrivute is null\n",
    "#they are not necessary for train or testing\n",
    "nullsEmpathy = d.data[\"Empathy\"].isnull().sum()\n",
    "#nullsEmpathy = 5\n",
    "print(\"Number of rows with Empathy that is null: \"+str(nullsEmpathy))\n",
    "d.data = d.data[d.data[\"Empathy\"].notna()]\n",
    "print(\"Number of rows with Empathy that is null after: \"+str(d.data[\"Empathy\"].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with the categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have to deal with the categorical variables. <br>\n",
    "The first thing that I have to do is to impute the missing values of them. I will use the mode() (which is the most common value for each feature) to impute them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idea, provare a predirre i valori mancanti!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical=d.data.select_dtypes(include=\"object\", exclude=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.data = d.data.select_dtypes(exclude=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Smoking                         tried smoking\n",
       "Alcohol                        social drinker\n",
       "Punctuality               i am always on time\n",
       "Lying                               sometimes\n",
       "Internet usage                few hours a day\n",
       "Gender                                 female\n",
       "Left - right handed              right handed\n",
       "Education                    secondary school\n",
       "Only child                                 no\n",
       "Village - town                           city\n",
       "House - block of flats         block of flats\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical.mode().loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoking                   8\n",
      "Alcohol                   5\n",
      "Punctuality               2\n",
      "Lying                     2\n",
      "Internet usage            0\n",
      "Gender                    6\n",
      "Left - right handed       3\n",
      "Education                 1\n",
      "Only child                2\n",
      "Village - town            4\n",
      "House - block of flats    4\n",
      "dtype: int64\n",
      "Smoking                   0\n",
      "Alcohol                   0\n",
      "Punctuality               0\n",
      "Lying                     0\n",
      "Internet usage            0\n",
      "Gender                    0\n",
      "Left - right handed       0\n",
      "Education                 0\n",
      "Only child                0\n",
      "Village - town            0\n",
      "House - block of flats    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(categorical.isnull().sum())\n",
    "categorical = categorical.fillna(categorical.mode().loc[0])\n",
    "print(categorical.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-hot encoding of categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalDummied = pd.get_dummies(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005, 34)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoricalDummied.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation of missing values for the numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wil use the mean value of each attribute to impute the value of missing values for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.data=d.data.fillna(d.data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.data= pd.concat([d.data,categoricalDummied],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls = d.data.isnull().sum()\n",
    "sorted([(x,y) for (x,y) in zip(nulls.index, nulls) if y>0], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005, 173)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split your data into 70% training data, 10% validation data and 20% test data. -> I will use cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = d.data.drop(columns=['Empathy'])\n",
    "Y = d.data['Empathy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have now to trasform the target feature from a scale from 1 to 5 to a binary variable 0 (if the vale is 1,2 or 3) and 1 (4 ot 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBinary(x):\n",
    "    res=[]\n",
    "    for i in range(len(x)):\n",
    "        if(x[i]<=3):\n",
    "            res.append(0)\n",
    "        else:\n",
    "            res.append(1)\n",
    "    res = np.array(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify=Y, test_size=0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train.values)\n",
    "Y_train=np.array(Y_train.values)\n",
    "X_test=np.array(X_test.values)\n",
    "Y_test=np.array(Y_test.values)\n",
    "Y=np.array(Y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use predict the most common or random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use as baseline a dump predictor that predict always the most frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_train=getBinary(Y_train)\n",
    "Y_test=getBinary(Y_test)\n",
    "Y=getBinary(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBaseline(x):\n",
    "    return scipy.stats.mode(x)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode=trainBaseline(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictBaseline(test,mostfrequent):\n",
    "    res=[]\n",
    "    for i in range(len(test)):\n",
    "        res.append(mostfrequent)\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=predictBaseline(X_test,mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6616915422885572"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predictions==Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usign the 20% of my dataset as testing set, this base predictor has an accuracy of 66%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start trying a Logistic Regression algoritm, I choose as solver the 'liblinear' one that should be one of the most suitable for binary classification in small databases. <br>\n",
    "I'll use the L2 norm for the penalization and a value of C very small. C is the inverse of regularization strength, like in support vector machines, smaller values specify stronger regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          n_jobs=None, penalty='l2', random_state=123, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logReg = LogisticRegression(solver='liblinear',random_state=123, C=0.1,penalty='l2', multi_class='ovr')\n",
    "logReg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = logReg.predict(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8208955223880597"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predict_train == Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = logReg.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7064676616915423"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predict_test == Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already achieved an accuracy of 82% on the training set and an accuracy of 70% on the testing one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will try to have a better idea of the real accuracy that that model can reach using a Stratified K-Fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005, 172)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7130555555555556"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(logReg, X, Y, cv=240))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model_simple = RandomForestClassifier()#20, \"gini\",10)\n",
    "model_simple = model_simple.fit(Xpca, yl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict3 = model_simple.predict(Xtpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict3 = getBinary(predict3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "principalComponents = pca.fit_transform(d.data)\n",
    "Xpca = pd.DataFrame(data = principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "principalComponents = pca.fit_transform(Xt)\n",
    "Xtpca = pd.DataFrame(data = principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56521739, 0.62222222, 0.6       , 0.64444444, 0.55555556,\n",
       "       0.64444444, 0.6       , 0.57777778, 0.53333333, 0.64444444,\n",
       "       0.77777778, 0.57777778, 0.53333333, 0.62222222, 0.6       ,\n",
       "       0.71111111, 0.64444444, 0.6       , 0.57777778, 0.68181818])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(model_simple, Xpca, yl, cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predict3 == check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "model4 = Lasso()\n",
    "model4 = model4.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict4 = model4.predict(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.98386772, 3.90664497, 4.01282624, 4.03213193, 3.7328938 ,\n",
       "       3.95490919, 4.05143761, 3.84872792, 3.98386772, 4.01282624,\n",
       "       3.96456203, 3.88733929, 3.98386772, 3.74254665, 4.01282624,\n",
       "       4.03213193, 3.99352056, 3.8680336 , 3.94525634, 4.03213193,\n",
       "       3.90664497, 3.83907507, 3.97421487, 4.09004899, 3.95490919,\n",
       "       4.08039614, 3.74254665, 4.08039614, 4.03213193, 3.99352056,\n",
       "       3.9356035 , 3.87768644, 3.91629782, 3.90664497, 4.06109046,\n",
       "       3.94525634, 3.98386772, 3.82942223, 3.71358812, 4.06109046,\n",
       "       3.83907507, 3.54948979, 3.98386772, 3.79081086, 3.97421487,\n",
       "       3.69428243, 3.78115802, 3.9356035 , 3.96456203, 3.91629782,\n",
       "       4.02247909, 3.71358812, 3.88733929, 3.94525634, 4.05143761,\n",
       "       3.87368811, 3.79081086, 3.97421487, 3.62671253, 3.79081086,\n",
       "       3.88733929, 3.98386772, 3.82942223, 3.79081086, 3.83907507,\n",
       "       3.72324096, 3.9356035 , 3.6653239 , 3.35643293, 3.81011654,\n",
       "       3.69428243, 3.91629782, 3.71358812, 3.9356035 , 3.64601822,\n",
       "       4.0031734 , 3.96456203, 3.83907507, 3.9356035 , 3.98386772,\n",
       "       4.0031734 , 3.9356035 , 3.74254665, 3.83907507, 3.99352056,\n",
       "       3.61705969, 3.74254665, 3.06684765, 3.98386772, 3.76185233,\n",
       "       4.0031734 , 3.8004637 , 4.0031734 , 3.50122558, 3.83907507,\n",
       "       3.91629782, 3.90664497, 3.81976939, 3.90664497, 3.9356035 ,\n",
       "       3.96456203, 3.74254665, 3.79081086, 3.95490919, 3.81976939])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict4=getBinary(predict4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6285714285714286"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predict4==check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It may be easier to have separate python files, but if you have a good way to make your code modular with one python file it is fine. What I mean is I should be able to run your testing code (e.g. loading your trained model -> get results on test data) only, instead of having to run the whole code for training -> testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y=d.data['Empathy']\n",
    "y=getBinary(y.values)\n",
    "x=d.data.drop(columns=['Empathy'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "            #    max_depth = 8, alpha = 10, n_estimators = 9000)\n",
    "xg_reg = xgb.XGBClassifier(n_estimators = 9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7284768211920529"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=110)\n",
    "principalComponents = pca.fit_transform(d.data.drop(columns=['Empathy']))\n",
    "Xpca = pd.DataFrame(data = principalComponents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y=d.data['Empathy']\n",
    "y=getBinary(y.values)\n",
    "x=d.data.drop(columns=['Empathy'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.1, random_state=123, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "            #    max_depth = 8, alpha = 10, n_estimators = 9000)\n",
    "xg_reg = xgb.XGBClassifier(objective = 'reg:logistic',max_depth = 5, n_estimators = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=3000,\n",
       "       n_jobs=1, nthread=None, objective='reg:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7128712871287128"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_reg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005, 138)"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.data.drop(columns=['Empathy']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data= d.data.drop(columns=['Empathy']), label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 0 pruned nodes, max_depth=4\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n",
      "[19:10:39] C:\\Users\\Administrator\\Desktop\\xgboost\\src\\tree\\updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\n"
     ]
    }
   ],
   "source": [
    "params = {\"objective\":\"reg:logistic\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.493092</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.495296</td>\n",
       "      <td>0.000355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.486119</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.490399</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.478217</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.485585</td>\n",
       "      <td>0.001383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.472533</td>\n",
       "      <td>0.001454</td>\n",
       "      <td>0.481503</td>\n",
       "      <td>0.001941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.467388</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.478056</td>\n",
       "      <td>0.001342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0         0.493092        0.000684        0.495296       0.000355\n",
       "1         0.486119        0.000487        0.490399       0.000142\n",
       "2         0.478217        0.000326        0.485585       0.001383\n",
       "3         0.472533        0.001454        0.481503       0.001941\n",
       "4         0.467388        0.000494        0.478056       0.001342"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7284768211920529"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(preds==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.6403798 ,  0.39789385,  0.13559869,  0.44253185,  0.5363653 ,\n",
       "        0.3591215 ,  0.7488286 ,  1.0237141 ,  0.4534249 ,  0.38871962,\n",
       "        0.9981936 ,  0.9865401 ,  0.84068537,  0.7939675 ,  0.70866823,\n",
       "        0.36939728,  0.78258705,  0.7433833 ,  0.16455597,  0.35075969,\n",
       "        0.39985213,  1.0550575 ,  0.5330728 ,  0.8424365 ,  0.23221496,\n",
       "        0.5966545 ,  0.85560167,  1.1549032 ,  0.91451657,  0.6247858 ,\n",
       "        0.64675033,  0.8124499 ,  0.5803994 ,  0.82452273,  0.6431018 ,\n",
       "        0.53773516,  0.48442534,  0.6484022 ,  0.556399  ,  0.62213856,\n",
       "        0.8358965 ,  0.16133097, -0.11745381,  0.31892183,  0.51258826,\n",
       "       -0.10482889,  1.0925102 ,  0.81104255,  0.9179917 ,  0.5875187 ,\n",
       "        0.65203476,  0.6049895 ,  1.0467666 ,  0.63754255,  0.60420376,\n",
       "        0.8833875 ,  0.4094634 ,  0.69907093,  0.75016105,  0.3766735 ,\n",
       "        0.7548522 ,  0.97776973,  1.1691058 ,  0.6546159 ,  0.6100499 ,\n",
       "        1.027824  ,  0.18218538,  0.60052484,  0.29500705,  0.47444552,\n",
       "        0.71189356,  0.79028887,  0.7103193 ,  0.93648314,  0.485797  ,\n",
       "        1.0007677 ,  0.59865224, -0.2705102 ,  0.5020042 ,  1.2445421 ,\n",
       "        0.7632085 ,  0.8956275 ,  0.5722853 ,  0.5397889 ,  0.5152443 ,\n",
       "        0.3604933 ,  0.9065964 ,  0.3240984 ,  0.8857515 ,  0.5693598 ,\n",
       "        0.82584786,  0.9635563 ,  0.34534937,  0.24586967,  0.39538738,\n",
       "        0.7699256 ,  0.4433584 , -0.28289688,  0.9043976 ,  0.28862262,\n",
       "        0.9644565 ,  0.56502914,  0.7192493 ,  0.39049584,  0.7263113 ,\n",
       "        0.6526575 ,  0.7741626 ,  1.0197096 ,  0.6499164 ,  0.56152254,\n",
       "        0.3618194 ,  0.891253  ,  0.88653934, -0.29934233,  0.9733851 ,\n",
       "        1.0863968 ,  0.972605  ,  1.132015  ,  0.14484704,  0.9812893 ,\n",
       "        0.5449683 ,  0.77020645,  0.6060253 ,  0.7866462 ,  0.59432197,\n",
       "        0.17458394,  0.86465   ,  0.53378093,  0.6978408 ,  0.630414  ,\n",
       "        0.87896264,  1.0244362 ,  1.165482  ,  1.0450182 ,  0.6717167 ,\n",
       "        0.1979537 ,  0.61800617,  0.51087797,  0.860858  ,  0.47290716,\n",
       "        0.98239684,  0.39837325,  0.51271445,  1.0820813 ,  0.54331374,\n",
       "        0.29102635,  0.45463353,  0.7196344 ,  0.3395587 ,  0.3693043 ,\n",
       "        0.94071853], dtype=float32)"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBClassifier(n_estimators = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7166666666666667"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(getBinary(preds)==getBinary(y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.,   4.,   2., ..., 186.,  98.,   1.],\n",
       "       [  5.,   3.,   5., ..., 180.,  80.,   1.],\n",
       "       [  5.,   5.,   5., ..., 176.,  53.,   3.],\n",
       "       ...,\n",
       "       [  5.,   3.,   3., ..., 171.,  49.,   3.],\n",
       "       [  5.,   4.,   5., ..., 176.,  55.,   1.],\n",
       "       [  5.,   3.,   2., ..., 192.,  90.,   1.]])"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "904/904 [==============================] - 3s 3ms/step - loss: 0.8467 - acc: 0.5841\n",
      "Epoch 2/200\n",
      "904/904 [==============================] - 0s 525us/step - loss: 0.6852 - acc: 0.6051\n",
      "Epoch 3/200\n",
      "904/904 [==============================] - 0s 541us/step - loss: 0.7028 - acc: 0.6073\n",
      "Epoch 4/200\n",
      "904/904 [==============================] - 0s 530us/step - loss: 0.7011 - acc: 0.5918\n",
      "Epoch 5/200\n",
      "904/904 [==============================] - 1s 554us/step - loss: 0.6776 - acc: 0.6327\n",
      "Epoch 6/200\n",
      "904/904 [==============================] - 0s 544us/step - loss: 0.6833 - acc: 0.6294\n",
      "Epoch 7/200\n",
      "904/904 [==============================] - 0s 534us/step - loss: 0.6762 - acc: 0.6361\n",
      "Epoch 8/200\n",
      "904/904 [==============================] - 0s 533us/step - loss: 0.6849 - acc: 0.6195\n",
      "Epoch 9/200\n",
      "904/904 [==============================] - 0s 542us/step - loss: 0.6821 - acc: 0.6040\n",
      "Epoch 10/200\n",
      "904/904 [==============================] - 0s 534us/step - loss: 0.6829 - acc: 0.6162\n",
      "Epoch 11/200\n",
      "904/904 [==============================] - 0s 553us/step - loss: 0.6783 - acc: 0.6261\n",
      "Epoch 12/200\n",
      "904/904 [==============================] - 0s 537us/step - loss: 0.6835 - acc: 0.6272\n",
      "Epoch 13/200\n",
      "904/904 [==============================] - 0s 520us/step - loss: 0.6846 - acc: 0.6294\n",
      "Epoch 14/200\n",
      "904/904 [==============================] - 0s 534us/step - loss: 0.6674 - acc: 0.6305\n",
      "Epoch 15/200\n",
      "904/904 [==============================] - 0s 540us/step - loss: 0.6716 - acc: 0.6239\n",
      "Epoch 16/200\n",
      "904/904 [==============================] - 1s 561us/step - loss: 0.6766 - acc: 0.6239\n",
      "Epoch 17/200\n",
      "904/904 [==============================] - 1s 556us/step - loss: 0.6865 - acc: 0.6018\n",
      "Epoch 18/200\n",
      "904/904 [==============================] - 0s 553us/step - loss: 0.6717 - acc: 0.6261\n",
      "Epoch 19/200\n",
      "904/904 [==============================] - 0s 539us/step - loss: 0.6889 - acc: 0.6206\n",
      "Epoch 20/200\n",
      "904/904 [==============================] - 1s 556us/step - loss: 0.6752 - acc: 0.6217\n",
      "Epoch 21/200\n",
      "904/904 [==============================] - 1s 560us/step - loss: 0.6722 - acc: 0.6460\n",
      "Epoch 22/200\n",
      "904/904 [==============================] - 0s 550us/step - loss: 0.6702 - acc: 0.6272\n",
      "Epoch 23/200\n",
      "904/904 [==============================] - 1s 570us/step - loss: 0.6952 - acc: 0.6150\n",
      "Epoch 24/200\n",
      "904/904 [==============================] - 0s 530us/step - loss: 0.6642 - acc: 0.6327\n",
      "Epoch 25/200\n",
      "904/904 [==============================] - 0s 535us/step - loss: 0.6694 - acc: 0.6460\n",
      "Epoch 26/200\n",
      "904/904 [==============================] - 1s 565us/step - loss: 0.6796 - acc: 0.6184\n",
      "Epoch 27/200\n",
      "904/904 [==============================] - 0s 523us/step - loss: 0.6738 - acc: 0.6383\n",
      "Epoch 28/200\n",
      "904/904 [==============================] - 0s 550us/step - loss: 0.6672 - acc: 0.6361\n",
      "Epoch 29/200\n",
      "904/904 [==============================] - 0s 524us/step - loss: 0.6596 - acc: 0.6383\n",
      "Epoch 30/200\n",
      "904/904 [==============================] - 0s 537us/step - loss: 0.6683 - acc: 0.6372\n",
      "Epoch 31/200\n",
      "904/904 [==============================] - 0s 533us/step - loss: 0.6683 - acc: 0.6438\n",
      "Epoch 32/200\n",
      "904/904 [==============================] - 0s 537us/step - loss: 0.6697 - acc: 0.6482\n",
      "Epoch 33/200\n",
      "904/904 [==============================] - 0s 537us/step - loss: 0.6701 - acc: 0.6350\n",
      "Epoch 34/200\n",
      "904/904 [==============================] - 0s 543us/step - loss: 0.6664 - acc: 0.6427\n",
      "Epoch 35/200\n",
      "904/904 [==============================] - 0s 544us/step - loss: 0.6724 - acc: 0.6305\n",
      "Epoch 36/200\n",
      "904/904 [==============================] - 0s 540us/step - loss: 0.6686 - acc: 0.6471\n",
      "Epoch 37/200\n",
      "904/904 [==============================] - 0s 532us/step - loss: 0.6671 - acc: 0.6338\n",
      "Epoch 38/200\n",
      "904/904 [==============================] - 0s 534us/step - loss: 0.6763 - acc: 0.6316\n",
      "Epoch 39/200\n",
      "904/904 [==============================] - 0s 551us/step - loss: 0.6697 - acc: 0.6316\n",
      "Epoch 40/200\n",
      "904/904 [==============================] - 0s 540us/step - loss: 0.6654 - acc: 0.6405\n",
      "Epoch 41/200\n",
      "904/904 [==============================] - 0s 546us/step - loss: 0.6528 - acc: 0.6493\n",
      "Epoch 42/200\n",
      "904/904 [==============================] - 0s 549us/step - loss: 0.6655 - acc: 0.6372\n",
      "Epoch 43/200\n",
      "904/904 [==============================] - 0s 534us/step - loss: 0.6635 - acc: 0.6560\n",
      "Epoch 44/200\n",
      "904/904 [==============================] - 0s 548us/step - loss: 0.6649 - acc: 0.6350\n",
      "Epoch 45/200\n",
      "904/904 [==============================] - 0s 547us/step - loss: 0.6675 - acc: 0.6394\n",
      "Epoch 46/200\n",
      "904/904 [==============================] - 0s 550us/step - loss: 0.6517 - acc: 0.6460\n",
      "Epoch 47/200\n",
      "904/904 [==============================] - 0s 540us/step - loss: 0.6618 - acc: 0.6449\n",
      "Epoch 48/200\n",
      "904/904 [==============================] - 0s 522us/step - loss: 0.6621 - acc: 0.6538\n",
      "Epoch 49/200\n",
      "904/904 [==============================] - 0s 527us/step - loss: 0.6634 - acc: 0.6493\n",
      "Epoch 50/200\n",
      "904/904 [==============================] - 0s 535us/step - loss: 0.6499 - acc: 0.6527\n",
      "Epoch 51/200\n",
      "904/904 [==============================] - 0s 540us/step - loss: 0.6615 - acc: 0.6593\n",
      "Epoch 52/200\n",
      "904/904 [==============================] - 0s 524us/step - loss: 0.6560 - acc: 0.6449\n",
      "Epoch 53/200\n",
      "904/904 [==============================] - 1s 625us/step - loss: 0.6624 - acc: 0.6327\n",
      "Epoch 54/200\n",
      "904/904 [==============================] - 1s 608us/step - loss: 0.6588 - acc: 0.6582\n",
      "Epoch 55/200\n",
      "904/904 [==============================] - 1s 555us/step - loss: 0.6506 - acc: 0.6493\n",
      "Epoch 56/200\n",
      "904/904 [==============================] - 0s 548us/step - loss: 0.6702 - acc: 0.6460\n",
      "Epoch 57/200\n",
      "904/904 [==============================] - 1s 579us/step - loss: 0.6560 - acc: 0.6471\n",
      "Epoch 58/200\n",
      "904/904 [==============================] - 1s 563us/step - loss: 0.6717 - acc: 0.6515\n",
      "Epoch 59/200\n",
      "904/904 [==============================] - 1s 555us/step - loss: 0.6527 - acc: 0.6593\n",
      "Epoch 60/200\n",
      "904/904 [==============================] - 1s 699us/step - loss: 0.6691 - acc: 0.6327\n",
      "Epoch 61/200\n",
      "904/904 [==============================] - 1s 609us/step - loss: 0.6566 - acc: 0.6538 0s - loss: 0.6643 - acc: 0.63 - ETA: 0s - loss: 0.6572 - acc: \n",
      "Epoch 62/200\n",
      "904/904 [==============================] - 0s 551us/step - loss: 0.6580 - acc: 0.6527\n",
      "Epoch 63/200\n",
      "904/904 [==============================] - 1s 736us/step - loss: 0.6504 - acc: 0.6515\n",
      "Epoch 64/200\n",
      "904/904 [==============================] - 1s 693us/step - loss: 0.6483 - acc: 0.6571\n",
      "Epoch 65/200\n",
      "904/904 [==============================] - 1s 744us/step - loss: 0.6574 - acc: 0.6515\n",
      "Epoch 66/200\n",
      "904/904 [==============================] - 1s 691us/step - loss: 0.6461 - acc: 0.6538\n",
      "Epoch 67/200\n",
      "904/904 [==============================] - 1s 690us/step - loss: 0.6409 - acc: 0.6593\n",
      "Epoch 68/200\n",
      "904/904 [==============================] - 1s 656us/step - loss: 0.6669 - acc: 0.6449\n",
      "Epoch 69/200\n",
      "904/904 [==============================] - 1s 700us/step - loss: 0.6585 - acc: 0.6504\n",
      "Epoch 70/200\n",
      "904/904 [==============================] - 1s 633us/step - loss: 0.6462 - acc: 0.6482\n",
      "Epoch 71/200\n",
      "904/904 [==============================] - 1s 714us/step - loss: 0.6525 - acc: 0.6604 0s - loss: 0.6538 - acc: 0.66\n",
      "Epoch 72/200\n",
      "904/904 [==============================] - 1s 715us/step - loss: 0.6591 - acc: 0.6527\n",
      "Epoch 73/200\n",
      "904/904 [==============================] - 1s 712us/step - loss: 0.6523 - acc: 0.6582\n",
      "Epoch 74/200\n",
      "904/904 [==============================] - 1s 701us/step - loss: 0.6523 - acc: 0.6593\n",
      "Epoch 75/200\n",
      "904/904 [==============================] - 1s 692us/step - loss: 0.6556 - acc: 0.6538\n",
      "Epoch 76/200\n",
      "904/904 [==============================] - 1s 672us/step - loss: 0.6567 - acc: 0.6571\n",
      "Epoch 77/200\n",
      "904/904 [==============================] - 1s 741us/step - loss: 0.6494 - acc: 0.6582\n",
      "Epoch 78/200\n",
      "904/904 [==============================] - 1s 584us/step - loss: 0.6465 - acc: 0.6604\n",
      "Epoch 79/200\n",
      "904/904 [==============================] - 0s 539us/step - loss: 0.6447 - acc: 0.6571\n",
      "Epoch 80/200\n",
      "904/904 [==============================] - 0s 523us/step - loss: 0.6548 - acc: 0.6593\n",
      "Epoch 81/200\n",
      "904/904 [==============================] - 0s 537us/step - loss: 0.6489 - acc: 0.6626\n",
      "Epoch 82/200\n",
      "904/904 [==============================] - 0s 540us/step - loss: 0.6559 - acc: 0.6615\n",
      "Epoch 83/200\n",
      "904/904 [==============================] - 1s 564us/step - loss: 0.6508 - acc: 0.6538\n",
      "Epoch 84/200\n",
      "904/904 [==============================] - 0s 544us/step - loss: 0.6498 - acc: 0.6571\n",
      "Epoch 85/200\n",
      "904/904 [==============================] - 1s 556us/step - loss: 0.6507 - acc: 0.6560\n",
      "Epoch 86/200\n",
      "904/904 [==============================] - 0s 553us/step - loss: 0.6537 - acc: 0.6515\n",
      "Epoch 87/200\n",
      "904/904 [==============================] - 1s 570us/step - loss: 0.6609 - acc: 0.6527\n",
      "Epoch 88/200\n",
      "904/904 [==============================] - 1s 562us/step - loss: 0.6474 - acc: 0.6604\n",
      "Epoch 89/200\n",
      "904/904 [==============================] - 1s 577us/step - loss: 0.6507 - acc: 0.6604\n",
      "Epoch 90/200\n",
      "904/904 [==============================] - 1s 572us/step - loss: 0.6549 - acc: 0.6593\n",
      "Epoch 91/200\n",
      "904/904 [==============================] - 1s 560us/step - loss: 0.6483 - acc: 0.6593\n",
      "Epoch 92/200\n",
      "904/904 [==============================] - 0s 540us/step - loss: 0.6496 - acc: 0.6604\n",
      "Epoch 93/200\n",
      "904/904 [==============================] - 0s 549us/step - loss: 0.6487 - acc: 0.6538\n",
      "Epoch 94/200\n",
      "904/904 [==============================] - 0s 553us/step - loss: 0.6547 - acc: 0.6560\n",
      "Epoch 95/200\n",
      "904/904 [==============================] - 1s 565us/step - loss: 0.6515 - acc: 0.6615\n",
      "Epoch 96/200\n",
      "904/904 [==============================] - 1s 556us/step - loss: 0.6527 - acc: 0.6615\n",
      "Epoch 97/200\n",
      "904/904 [==============================] - 0s 528us/step - loss: 0.6442 - acc: 0.6626\n",
      "Epoch 98/200\n",
      "904/904 [==============================] - 0s 538us/step - loss: 0.6469 - acc: 0.6604\n",
      "Epoch 99/200\n",
      "128/904 [===>..........................] - ETA: 0s - loss: 0.6343 - acc: 0.6719"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-592-ee2e549f10fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cs412\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1361\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cs412\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    262\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cs412\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2912\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2914\u001b[1;33m     \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2915\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2916\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cs412\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dense(256, activation=tf.nn.tanh),\n",
    "  tf.keras.layers.Dropout(0.2), #it was 0.2\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train.values, y_train , epochs=200)\n",
    "model.evaluate(X_test.values, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prova SVM ! && cross validation per RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
